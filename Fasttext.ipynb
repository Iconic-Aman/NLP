{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module fasttext.FastText in fasttext:\n",
      "\n",
      "NAME\n",
      "    fasttext.FastText\n",
      "\n",
      "DESCRIPTION\n",
      "    # Copyright (c) 2017-present, Facebook, Inc.\n",
      "    # All rights reserved.\n",
      "    #\n",
      "    # This source code is licensed under the MIT license found in the\n",
      "    # LICENSE file in the root directory of this source tree.\n",
      "\n",
      "FUNCTIONS\n",
      "    cbow(*kargs, **kwargs)\n",
      "    \n",
      "    eprint(*args, **kwargs)\n",
      "    \n",
      "    load_model(path)\n",
      "        Load a model given a filepath and return a model object.\n",
      "    \n",
      "    read_args(arg_list, arg_dict, arg_names, default_values)\n",
      "    \n",
      "    skipgram(*kargs, **kwargs)\n",
      "    \n",
      "    supervised(*kargs, **kwargs)\n",
      "    \n",
      "    tokenize(text)\n",
      "        Given a string of text, tokenize it and return a list of tokens\n",
      "    \n",
      "    train_supervised(*kargs, **kwargs)\n",
      "        Train a supervised model and return a model object.\n",
      "        \n",
      "        input must be a filepath. The input text does not need to be tokenized\n",
      "        as per the tokenize function, but it must be preprocessed and encoded\n",
      "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "        \n",
      "        The input file must must contain at least one label per line. For an\n",
      "        example consult the example datasets which are part of the fastText\n",
      "        repository such as the dataset pulled by classification-example.sh.\n",
      "    \n",
      "    train_unsupervised(*kargs, **kwargs)\n",
      "        Train an unsupervised model and return a model object.\n",
      "        \n",
      "        input must be a filepath. The input text does not need to be tokenized\n",
      "        as per the tokenize function, but it must be preprocessed and encoded\n",
      "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "        \n",
      "        The input field must not contain any labels or use the specified label prefix\n",
      "        unless it is ok for those words to be ignored. For an example consult the\n",
      "        dataset pulled by the example script word-vector-example.sh, which is\n",
      "        part of the fastText repository.\n",
      "\n",
      "DATA\n",
      "    BOW = '<'\n",
      "    EOS = '</s>'\n",
      "    EOW = '>'\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    displayed_errors = {}\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 1310...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    unicode_literals = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', ...\n",
      "    unsupervised_default = {'autotuneDuration': 300, 'autotuneMetric': 'f1...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\amana\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\fasttext\\fasttext.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext.FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(\"C:\\\\Users\\\\amana\\\\Downloads\\\\cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8350069522857666, 'cats'),\n",
       " (0.8233457207679749, 'kitty'),\n",
       " (0.8083016276359558, 'kitten'),\n",
       " (0.7533658742904663, 'feline')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors(\"cat\", k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.08105576, -0.02083234, -0.03326922,  0.28555283,  0.13959414,\n",
       "       -0.1977245 ,  0.10128298,  0.01085356, -0.103824  ,  0.04313416,\n",
       "       -0.14833796, -0.16765352, -0.15447043, -0.14154345,  0.12743813,\n",
       "        0.2279076 ,  0.07685639, -0.13873424, -0.20190817,  0.01528534,\n",
       "       -0.06999817,  0.11306947,  0.01669297,  0.11389008,  0.02094817,\n",
       "       -0.31620952,  0.09814467, -0.1449248 ,  0.09949644,  0.2211973 ,\n",
       "        0.02225026,  0.06751259, -0.06465218,  0.11267239, -0.0256991 ,\n",
       "       -0.04765478,  0.03917777,  0.00168321, -0.11691307, -0.27667975,\n",
       "       -0.06021226,  0.11350961, -0.11300616,  0.08379158, -0.21970375,\n",
       "        0.06771149,  0.0296645 , -0.05783203, -0.12882547,  0.09360313,\n",
       "       -0.0628323 , -0.08581617,  0.17381558, -0.10044617, -0.28967732,\n",
       "       -0.01837742,  0.01613754, -0.0155128 , -0.11910667,  0.20571907,\n",
       "        0.2338278 ,  0.17166924,  0.07774843,  0.05795193, -0.05462614,\n",
       "       -0.05604232,  0.07913449,  0.32939437, -0.21045874, -0.11304444,\n",
       "        0.0575723 ,  0.0240243 ,  0.04918412, -0.00123884, -0.19010013,\n",
       "       -0.13446511,  0.21461043, -0.03400415,  0.01046168,  0.07740843,\n",
       "        0.16205223, -0.05187377, -0.10297765, -0.2242473 , -0.05481768,\n",
       "        0.02777104,  0.04504567,  0.0280448 ,  0.08349931, -0.0947693 ,\n",
       "       -0.08598264, -0.3568015 ,  0.12311324,  0.02738705, -0.00785374,\n",
       "        0.08330573,  0.19943208,  0.04547388,  0.18876314,  0.14724758,\n",
       "       -0.36264786,  0.10352075,  0.04481024, -0.03069196, -0.04293906,\n",
       "        0.04981232, -0.29237306,  0.3312763 ,  0.01118911, -0.01366141,\n",
       "        0.04181359,  0.00797943, -0.22261557,  0.08079234,  0.04292822,\n",
       "       -0.04677371, -0.17992711,  0.1144486 , -0.0288674 ,  0.0880094 ,\n",
       "       -0.18215865, -0.01429704, -0.00713941, -0.07557592,  0.07363671,\n",
       "        0.15832493, -0.12818596,  0.23811077,  0.21621591, -0.15509972,\n",
       "       -0.11514035, -0.00113345, -0.0628226 , -0.19765827, -0.06681902,\n",
       "        0.03757597,  0.18216723,  0.10831188, -0.01181745, -0.00282417,\n",
       "       -0.22391851, -0.11692671,  0.17321527,  0.01555726, -0.12287116,\n",
       "       -0.01001604, -0.29298973,  0.15872392, -0.00717149, -0.11472785,\n",
       "        0.01296498, -0.20333676, -0.05006766,  0.00861594, -0.18058869,\n",
       "       -0.09512712,  0.05120578,  0.00669428, -0.1353175 ,  0.10309117,\n",
       "       -0.08428084,  0.23800498,  0.19420755, -0.04042051, -0.05327505,\n",
       "       -0.14226167,  0.5043118 , -0.04709461,  0.07587084,  0.0368096 ,\n",
       "       -0.17633967,  0.20457302, -0.35128823,  0.07051338,  0.00201938,\n",
       "        0.05197956,  0.13930053,  0.07853405, -0.28847766,  0.07748775,\n",
       "        0.11528099, -0.01693372,  0.02308177, -0.17261219,  0.18667871,\n",
       "        0.10301095,  0.20211388, -0.04852751,  0.00952623,  0.04364521,\n",
       "       -0.2666222 , -0.12237131,  0.10129285,  0.05666918,  0.2079553 ,\n",
       "        0.0933083 ,  0.03482562,  0.1169966 , -0.06999424,  0.07376687,\n",
       "       -0.16195787,  0.02173381,  0.05140361,  0.18888497, -0.04526789,\n",
       "        0.11575621,  0.07859205, -0.04566301,  0.12501785,  0.16399984,\n",
       "       -0.04043661, -0.1042885 , -0.05033493, -0.19847214, -0.07339809,\n",
       "       -0.10427585, -0.00584699, -0.15202472,  0.08722179, -0.02139931,\n",
       "        0.06991025, -0.06449134, -0.03493118,  0.00490016,  0.0246936 ,\n",
       "       -0.10078498,  0.08396043, -0.1062537 , -0.13869871, -0.09136061,\n",
       "        0.12302251,  0.06168437,  0.02954458,  0.03203412,  0.04786261,\n",
       "        0.01925538, -0.09616736,  0.0912177 , -0.05313204,  0.29551613,\n",
       "       -0.07371814, -0.07504821, -0.3178438 , -0.1746165 ,  0.11554234,\n",
       "        0.13955456, -0.0468085 , -0.04206348,  0.00883872,  0.10709482,\n",
       "        0.0287071 , -0.06932212, -0.05080307, -0.0382563 , -0.28113165,\n",
       "        0.08925261,  0.05306546, -0.13811952,  0.0362194 , -0.12643738,\n",
       "       -0.21391355, -0.11981697, -0.03300172, -0.22084385, -0.14211643,\n",
       "       -0.01799391, -0.01686784,  0.1613175 , -0.07888834, -0.0905152 ,\n",
       "        0.00529774, -0.05524676, -0.16600847,  0.04176328, -0.2638812 ,\n",
       "        0.02039177, -0.03363415,  0.15648663, -0.10055929, -0.12960714,\n",
       "       -0.12374973, -0.07323535, -0.17085005,  0.18332428, -0.03379165,\n",
       "       -0.04543614, -0.05318792, -0.11366287, -0.04781571, -0.19407704,\n",
       "       -0.05102151,  0.1296857 , -0.10509466,  0.18691303, -0.02298218,\n",
       "       -0.22713184, -0.22551058,  0.21606588,  0.06902882,  0.06388879],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.get_word_vector('cat').shape)\n",
    "model.get_word_vector('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7099694013595581, 'germany'),\n",
       " (0.6803402900695801, 'austria'),\n",
       " (0.6357281804084778, 'greece'),\n",
       " (0.632602870464325, 'europe'),\n",
       " (0.6102869510650635, 'france'),\n",
       " (0.5975680947303772, 'belgium'),\n",
       " (0.5884956121444702, 'japan'),\n",
       " (0.5878781676292419, 'leipzig'),\n",
       " (0.5863924026489258, 'düsseldorf'),\n",
       " (0.5818359851837158, 'berlin.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies('india', 'delhi', 'berlin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5730387568473816, 'driving'),\n",
       " (0.5610768795013428, 'drivng'),\n",
       " (0.5399937033653259, 'driving.I'),\n",
       " (0.535627007484436, 'driving.If'),\n",
       " (0.5268257260322571, 'cars'),\n",
       " (0.5186623930931091, 'driving.In'),\n",
       " (0.5181958079338074, 'car.Also'),\n",
       " (0.51544588804245, 'driving.It'),\n",
       " (0.5078772902488708, 'car.So'),\n",
       " (0.5072080492973328, 'vehicle')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies('reading', 'book', 'car')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
